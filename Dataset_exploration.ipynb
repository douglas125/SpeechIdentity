{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd95c178",
   "metadata": {},
   "source": [
    "# Dataset exploration\n",
    "\n",
    "This notebook helps understand the Mozilla Speech dataset https://commonvoice.mozilla.org/en/datasets\n",
    "\n",
    "The version under analysis is Common Voice Corpus 6.1. In particular, it is necessary to download file `en.tar` and place it in `data` folder.\n",
    "\n",
    "We know that the corpus was collected using mono, 16 bit, 48 kHz - see https://arxiv.org/abs/1912.06670."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5074e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from IPython.display import Audio\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "audio_tarfile = 'data/en.tar'\n",
    "en_total = 1584330\n",
    "\n",
    "if audio_tarfile.endswith('.tar'):\n",
    "    audios_tar = tarfile.open(audio_tarfile, 'r')\n",
    "elif self.audio_tarfile.endswith('.tar.gz'):\n",
    "    audios_tar = tarfile.open(audio_tarfile, \"r:gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7b5df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the English tarfile, we already know the max\n",
    "tar_file_list = [x for x in tqdm(audios_tar, total=en_total)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be143b46",
   "metadata": {},
   "source": [
    "## Analyze validated files\n",
    "\n",
    "The tar file contains train, dev and test splits (see [this thread](https://discourse.mozilla.org/t/why-train-tsv-includes-a-few-files-just-3-of-validated-set/36471/5) for extra explanation).\n",
    "\n",
    "Let's take a look at them:\n",
    "\n",
    "- Search for the files inside tar file\n",
    "- Read contents using pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34adaacb",
   "metadata": {},
   "source": [
    "### Sanity checks\n",
    "\n",
    "Verify if the files are available and make sure that the splits are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23101c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {\n",
    "    'train.tsv': None,\n",
    "    'dev.tsv': None,\n",
    "    'test.tsv': None,\n",
    "    # 'validated.tsv': None\n",
    "}\n",
    "n_files = len(data_files.keys())\n",
    "cur_files = 0\n",
    "\n",
    "for x in tar_file_list:\n",
    "    for k in data_files:\n",
    "        if x.name.endswith(k):\n",
    "            with audios_tar.extractfile(x) as f:\n",
    "                df = pd.read_csv(f, sep='\\t')\n",
    "                data_files[k] = df\n",
    "            cur_files += 1\n",
    "    if cur_files == n_files:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac006e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are client_ids leaking\n",
    "for x in data_files.keys():\n",
    "    for y in data_files.keys():\n",
    "        if x != y:\n",
    "            intersec_elems = set(data_files[x].client_id).intersection(set(data_files[y].client_id))\n",
    "            assert len(intersec_elems) == 0, f'Repeated ids in sets {x} and {y}'\n",
    "        else:\n",
    "            print(f'{x} has {len(set(data_files[x].client_id))} unique ids and {len(data_files[x])} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08403e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out the mp3 folder inside tar\n",
    "\n",
    "for x in audios_tar:\n",
    "    if x.name.endswith('.mp3'):\n",
    "        mp3_folder = x.name.split('/')\n",
    "        mp3_folder = '/'.join(mp3_folder[:-1])\n",
    "        break\n",
    "print(f'Detected mp3 folder: {mp3_folder}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8495dcef",
   "metadata": {},
   "source": [
    "### Load, plot and analyze a random audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fa88ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = np.random.randint(len(data_files['train.tsv']))\n",
    "sample = data_files['train.tsv'].iloc[sample_idx]\n",
    "sample_idx, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffebe489",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_info = [x for x in tar_file_list if x.name.endswith(sample.path)][0]\n",
    "\n",
    "# read file content\n",
    "mp3_file = audios_tar.extractfile(sample_info)\n",
    "mp3_content = mp3_file.read()\n",
    "\n",
    "sr = 48000\n",
    "decoded_mp3 = tfio.audio.decode_mp3(mp3_content, shape=None, name=None)\n",
    "\n",
    "# listen to audio\n",
    "\n",
    "Audio(decoded_mp3.numpy()[:, 0], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d2e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(len(decoded_mp3)) / sr\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.title('Waveform')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Intensity')\n",
    "plt.plot(t, decoded_mp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6f0468",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_stride = 256\n",
    "spec_len = 1024\n",
    "\n",
    "spectrogram = tfio.audio.spectrogram(\n",
    "    decoded_mp3[:, 0], nfft=spec_len, window=spec_len, stride=spec_stride)\n",
    "spectrogram = tf.transpose(spectrogram)\n",
    "\n",
    "spectrogram_t = np.arange(spectrogram.shape[1]) * spec_stride / sr\n",
    "spectrogram_f = np.arange(spectrogram.shape[0]) * sr / spec_len\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.title('Spectrogram')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "\n",
    "plt.ylim(0, 10000)\n",
    "\n",
    "plt.pcolormesh(\n",
    "    spectrogram_t,\n",
    "    spectrogram_f,\n",
    "    tf.math.log(spectrogram).numpy(),\n",
    "    shading='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d2e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warp the linear scale spectrograms into the mel-scale.\n",
    "spectrogram = tf.transpose(spectrogram)\n",
    "num_spectrogram_bins = spectrogram.shape[-1]\n",
    "lower_edge_hertz, upper_edge_hertz, num_mel_bins = 80.0, 10000.0, 85\n",
    "linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
    "  num_mel_bins, num_spectrogram_bins, sr, lower_edge_hertz,\n",
    "  upper_edge_hertz)\n",
    "mel_spectrograms = tf.tensordot(\n",
    "  spectrogram, linear_to_mel_weight_matrix, 1)\n",
    "mel_spectrograms.set_shape(spectrogram.shape[:-1].concatenate(\n",
    "  linear_to_mel_weight_matrix.shape[-1:]))\n",
    "\n",
    "# Compute a stabilized log to get log-magnitude mel-scale spectrograms.\n",
    "\n",
    "log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n",
    "log_mel_spectrograms = tf.transpose(log_mel_spectrograms)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.title('Mel frequency spectrogram')\n",
    "\n",
    "pcol = plt.pcolormesh(\n",
    "    log_mel_spectrograms.numpy(),\n",
    "    shading='auto',\n",
    "    linewidth=0, rasterized=True\n",
    ")\n",
    "pcol.set_edgecolor('face')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7671373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
